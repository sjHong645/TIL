[출처](https://www.samsungsds.com/kr/insights/1233713_4627.html)

## 병렬화 

`병렬 프로그래밍`은 순차적인 직렬프로그램을 분할해 `분할한 단위`를 `동시에 병렬로 수행`함으로써 성능을 향상시키는 프로그래밍 기술.  
이러한 전반적인 과정을 `병렬화`라고 한다. 

### 병렬화 단계 
![image](https://user-images.githubusercontent.com/64796257/196320678-3167f066-e46a-4ed9-ac21-bf83c6fb4065.png)

각 단계에 대해서 살펴보겠다. 

#### 1. 병렬화 대상 찾기 

병렬화를 수행할 때 가장 먼저 해야 할 일이다.  
즉, 순차적인 코드에서 `가장 많은 시간`이 소요되는 `병목 구간`을 찾는 과정이다. 

이런 작업은 프로그래머가 직접 코드를 살펴보며 찾을 수도 있지만 일반적으로는 `프로파일링 도구`를 사용해서 찾아낸다.  

ex) Intel 사의 VTune / AMD 사의 CodeAnlyst/ 오픈소스 oprofile 등 

`병렬화 대상`을 찾아내어 실제 병렬화를 했을 때 `성능이 어디까지 향상`될 수 있을지 `Amdahl's law(암달의 법칙)`을 이용해 예측할 수 있다. 

![image](https://user-images.githubusercontent.com/64796257/196321463-41b4d89d-3eca-4831-9f54-0d31cf0c8031.png)

```
P : 병렬화 비율 
S : 순서대로 실행하는 비율 

그래서 S와 P는 S+P = 1이라는 관계를 갖는다. 

N : 실행할 수 있는 코어 개수 
```

#### 2. 의존성 분석 

병렬화 대상을 찾았다면 `실제 병렬화`가 `가능`한지 확인해야 한다.  
즉, 병렬화를 하기 위해 `프로그램을 분할`할 때 서로 간에 `의존성 없이 동시에 수행 가능한지`의 여부를 찾아보는 과정이다. 

대표적인 의존성 분석은 다음과 같다. 

① Flow Dependency (Read-After-Write; RAW) 

이전 명령의 연산결과를 후속 명령에서 읽으려고 시도할 때 발생하는 의존성 문제 

ex) 
```
a = b + c; // 명령 1
d = a + e; // 명령 2
```

`명령 2`는 `명령 1`의 연산이 완료되어 `a값`이 결정되야만 수행할 수 있다. 이런 경우 두 명령은 병렬화 수행이 불가하다. 

② Anti-Dependency (Write-After-Read; WAR) 

후속 명령이 이전 명령에서 값을 읽기 전에 값을 쓰려고 할 때 발생하는 의존성 문제 

```
a = b + c; // 명령 1
b = d + e; // 명령 2
```

`명령 1`에서 `b값`을 먼저 읽은 후 `명령 2`에서 b값을 써야 하므로 두 명령은 병렬화 수행이 불가하다. 

③ Outer Dependency (Write-After-Write; WAW) 

`이전 명령`에서 값을 쓰기 전에 `후속 명령`이 값을 쓰려고 할 때 발생하는 의존성 문제 

```
a = b + c; // 명령 1
a = d + e; // 명령 2
```

`명령 1`에서 `a값`을 먼저 쓰고 나서 `명령 2`에서 a값을 써야 하므로 두 명령은 병렬화 수행이 불가하다. 

#### 3. 병렬화 패턴 결정 

병렬화가 가능하다고 판단했다면 이제 `병렬화 대상의 속성`에 따라 어떤 방식으로 병렬화를 진행할지 `패턴을 결정`해야 한다.  
크게 `데이터 병렬화`, `태스크 병렬화`로 구분된다. 

- 데이터 병렬화 (벡터화) 

: `데이터 집합`을 분해한 뒤, 각 프로세서에 할당하여 `동일한 연산`을 `동시에 수행`하는 기술. 

![image](https://user-images.githubusercontent.com/64796257/196332122-824cfcee-cece-4e99-a1e9-0cce6580e80c.png)

예를 들어 `A[n] + B[n] = C[n]`이라는 연산을 처리할 때  
`순차처리 방식`에서는 for문 내의 각 데이터 연산이 순서대로 수행되기 때문에 시간이 많이 소요된다. 

하지만, 연산을 처리하는 core가 n개이고 각 연산이 `서로 의존성이 없는 경우` 동시에 병렬처리가 가능하다.  
이러한 방식을 `데이터 병렬화`라고 한다. 

Intel의 SSE, AVX 등의 SIMD 아키텍처 및 GPGPU 기술은 이러한 데이터 병렬화에 최적화된 기술이라 볼 수 있다. 

- 태스크 병렬화 

수행해야 할 작업들을 `기능별`로 분해한 뒤 `각 프로세서에 할당`하여 서로 다른 기능들을 동시에 수행하는 기술 

![image](https://user-images.githubusercontent.com/64796257/196339479-b1d035aa-aa83-408f-a779-870f2f350f97.png)

예를 들어, `Task 1`은 I/O 작업 / `Task 2`는 연산 작업 등을 맡겨 서로 다른 기능들을 동시에 수행할 수 있도록 하는 기술이 태스크 병렬화다. 

보통 `기능적 단위`로 수행되기 때문에 
- `범용 CPU`를 활용한 병렬컴퓨터 구조에서 주로 구현이 가능함 
- `멀티스레드 방식`에서는 하나의 스레드가 하나의 task를 맡아 수행하는 구조로 동작한다. 

#### 4. 병렬프로그래밍 구현 

① 공유 메모리 병렬프로그래밍 모델

SMP나 CMP 등의 `공유 메모리 시스템 구조`에 적합한 방식으로써 `다수의 코어의 협력`을 통해 병렬화를 수행하는 모델 

이 모델에서는 `여러 개의 스레드를 생성`한 후 `다수의 코어로 분해`하여 병렬처리를 수행하는데  
스레드의 생성 및 처리를 위해 일반적으로 UNIX 계열의 POSIX 표준의 `pthread`라는 API를 활용한다. 

하지만, `pthread`는 스레드 생성, 병렬화, 동기화 등 신경써야 할 부분이 많다.   
그래서 다음과 같은 도구들이 고안되었다. 
- C/C++/Fortran 기반의 병렬 프로그래밍 API `OpenMP`
- C++ 기반의 인텔의 `TBB`, `Clik++` 
- .Net FW 4.0 버전 이상부터 사용가능한 `TPL`라이브러리

② 메시지 패싱 병렬프로그래밍 모델

- MPI (Message Passing Interface)
`분산 메모리 시스템 구조`에 적합한 병렬 프로그래밍 모델  
MPI에서는 `노드 간의 네트워크`를 통해 `메시지를 주고받는 형태`로 정보를 공유한다. 

따라서, `통신 속도`가 성능의 매우 중요한 요소로 작용되며 고속의 연산처리를 필요로 하는 슈퍼컴퓨터에서 많이 사용된다. 

- MapReduce 

하둡 클러스터에서 사용되는 `맵리듀스`는 `빅데이터 처리에 적합`하게 설계된 모델이다. 

`HDFS`라는 `분산 파일 시스템`을 사용해 `대규모 데이터를 저장 및 처리`하는 메커니즘을 갖고 있다.  
또한 특정 노드에 장애가 발생해도 `다른 노드를 통해` 중단없이 작업을 진행할 수 있는 특징을 갖고 있다. 

③ 가속기 병렬프로그래밍 모델 

①, ②에서 살펴본 모델은 모두 `범용 CPU`를 활용한 병렬 프로그래밍 모델이다.   
특정 연산에 특화된 `가속기`를 활용하여 병렬화한 모델을 `가속기 병렬 프로그래밍 모델`이라 한다. 

단순하고 반복적인 수치계산에 최적화된 CPU, DSP, GPU 등을 활용하는 프로그래밍 모델이라고 볼 수 있다.  
또한, `수치계산에 최적화`되어 있으므로 `데이터 병렬화`에 주로 사용된다. 

- 대표적인 기술
1) GPU를 활용한 `GPGPU` 기술 ⇒ 현재는 `GPGPU`를 지원하기 위한 다양한 FW가 나와있는 상황 

NVIDA에서 만든 `CUDA` / CUDA를 추상화해 손쉽게 프로그래밍 할 수 있는 `OpenACC`가 대표적이다. 

2) OpenCL(Open Computing Language) 

GPU뿐만 아니라 CPU, DSP, Cell 등 다양한 `이기종 컴퓨팅 환경`에서 사용할 수 있도록 표준화된 환경을 제공하고 있다. 

### 동기화 

[관련 내용](https://github.com/sponbob-pat/TIL/blob/main/CS/Operating_System/11th_week.md)

지금까지 프로그램의 성능을 향상시키기 위해 병렬화하는 과정을 함께 살펴봤다.  
하지만 병렬 프로그램 코드를 작성할 때, 매우 중요한 요소가 있는데 바로 `동기화`다.  

여러 개의 task 들이 병렬로 실행될 때 `동일한 자원`을 공유해야 하는 경우가 발생한다.  
이러한 자원을 `공유자원`이라 하는데 다수의 task가 공유자원을 `동시에 변경`하고자 하는 경우, 공유자원은 예상치 못한 값이 될 수 있다.

따라서, `하나의 task`가 공유자원을 변경하는 동안 `다른 task`가 해당 자원을 변경하지 못하도록 `atomicity`를 보장해야 하는데  
이를 해결하기 위한 방법이 바로 `동기화(Synchronization)`다. 

그럼 공유 메모리 병렬 프로그래밍 모델의 `멀티스레드 방식을 예시`로 하여 동기화에 대해 살펴보자 

#### 데이터 레이스(Data Race) 

`2개 이상의 쓰레드들`이 공유자원에 `동시에 접근`하는 상황을 `데이터 레이스`라 한다.  
`읽기(read)` 작업은 문제가 되지 않지만 하나 이상의 쓰레드가 `쓰기(write)` 작업을 시도하는 경우  

다른 쓰레드들은 공유자원에 대해 `전혀 예측하지 못한` 값을 참조할 수 있다. 

![image](https://user-images.githubusercontent.com/64796257/196585427-3306ba31-5bf6-4382-90f6-9b45f5b23cad.png)

이런 문제를 해결하기 위해 `하나의 쓰레드`가 작업을 진행하는 동안 `다른 쓰레드들`은 작업을 멈추고 대기하는 메커니즘이 필요하다. 

#### 동기화 종류 

- 기본적인 알고리즘 

1) 작업을 진행 중인 쓰레드는 `lock`을 통해 작업에 대한 `원자성`을 확보 
2) `나머지 쓰레드들`은 `wait`를 통해 대기한다.

- OS에서 제공하는 동기화 장치들 
![image](https://user-images.githubusercontent.com/64796257/196585531-0b3cd935-dbcf-4f63-8e86-770fcfce43e2.png)
